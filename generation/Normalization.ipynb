{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyMMmA9QDIuJZqecp1CPzPtx"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import pandas as pd\n","from torch.utils.data import DataLoader, TensorDataset\n","from torch.nn.utils.rnn import pack_padded_sequence\n","from tqdm import tqdm\n","import os\n","from google.colab import drive\n","\n","# 1. Setup Environment\n","drive.mount('/content/drive')\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","config = {\n","    \"max_length\": 50,\n","    \"embedding_dim\": 128,\n","    \"hidden_dim\": 512,\n","    \"latent_dim\": 64,\n","    \"batch_size\": 4096\n","}\n","\n","# 3. CLASS DEFINITIONS\n","class PeptideTokenizer:\n","    def __init__(self):\n","        self.chars = ['<PAD>', '<SOS>', '<EOS>', '<UNK>'] + list(\"ACDEFGHIKLMNPQRSTVWY\")\n","        self.char_to_idx = {c: i for i, c in enumerate(self.chars)}\n","        self.idx_to_char = {i: c for i, c in enumerate(self.chars)}\n","        self.vocab_size = len(self.chars)\n","\n","    def encode_batch(self, seqs, max_len):\n","        batch_tensor = torch.full((len(seqs), max_len), self.char_to_idx['<PAD>'], dtype=torch.long)\n","        lengths = []\n","        for i, seq in enumerate(tqdm(seqs, desc=\"Tokenizing\")):\n","            s = seq[:max_len - 2]\n","            idx = [self.char_to_idx.get(aa, self.char_to_idx['<UNK>']) for aa in s]\n","            full_seq = [self.char_to_idx['<SOS>']] + idx + [self.char_to_idx['<EOS>']]\n","            length = len(full_seq)\n","            batch_tensor[i, :length] = torch.tensor(full_seq)\n","            lengths.append(length)\n","        return batch_tensor, torch.tensor(lengths, dtype=torch.long)\n","\n","    def decode(self, indices):\n","        res = []\n","        for idx in indices:\n","            if idx == self.char_to_idx['<EOS>']: break\n","            if idx in [self.char_to_idx['<SOS>'], self.char_to_idx['<PAD>']]: continue\n","            res.append(self.idx_to_char[idx])\n","        return \"\".join(res)\n","\n","class VAE(nn.Module):\n","    def __init__(self, vocab_size, emb_dim, hidden_dim, latent_dim):\n","        super(VAE, self).__init__()\n","        self.embedding = nn.Embedding(vocab_size, emb_dim)\n","        self.encoder_gru = nn.GRU(emb_dim, hidden_dim, batch_first=True, bidirectional=True)\n","        self.fc_mu = nn.Linear(hidden_dim * 2, latent_dim)\n","        self.fc_logvar = nn.Linear(hidden_dim * 2, latent_dim)\n","        self.decoder_input = nn.Linear(latent_dim, hidden_dim)\n","        self.decoder_gru = nn.GRU(emb_dim, hidden_dim, batch_first=True)\n","        self.fc_out = nn.Linear(hidden_dim, vocab_size)\n","\n","    def forward(self, x, lengths):\n","        embedded = self.embedding(x)\n","        packed_input = pack_padded_sequence(embedded, lengths.cpu(), batch_first=True, enforce_sorted=False)\n","        _, hidden = self.encoder_gru(packed_input)\n","        hidden_cat = torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim=1)\n","        mu = self.fc_mu(hidden_cat)\n","        return mu # We only need MU for extraction\n","\n","# 4. PATHS\n","MODEL_PATH = \"/content/drive/MyDrive/AMP-Generation/models/vae_FINAL_epoch20.pth\"\n","STATS_PATH = \"/content/drive/MyDrive/AMP-Generation/models/vae_correction_stats.pth\"\n","POS_DATA   = \"/content/drive/MyDrive/AMP-Generation/data/pos_data.csv\"\n","NEG_DATA   = \"/content/drive/MyDrive/AMP-Generation/data/neg_data.csv\"\n","\n","# 5. INITIALIZE & LOAD\n","tokenizer = PeptideTokenizer()\n","model = VAE(\n","    vocab_size=tokenizer.vocab_size,\n","    emb_dim=config[\"embedding_dim\"],\n","    hidden_dim=config[\"hidden_dim\"],\n","    latent_dim=config[\"latent_dim\"]\n",").to(device)\n","\n","# Load model weights\n","checkpoint = torch.load(MODEL_PATH, map_location=device)\n","if isinstance(checkpoint, dict) and 'model_state_dict' in checkpoint:\n","    model.load_state_dict(checkpoint['model_state_dict'])\n","else:\n","    model.load_state_dict(checkpoint)\n","model.eval()\n","\n","# Load stats\n","stats = torch.load(STATS_PATH, map_location=device)\n","mu_mean = stats['shift'].to(device)\n","mu_std = stats['scale'].to(device)\n","\n","# 6. EXTRACTION FUNCTION\n","def extract_and_normalize(csv_path, output_filename):\n","    print(f\"Converting {os.path.basename(csv_path)} to Latent Space...\")\n","    df = pd.read_csv(csv_path)\n","    col = 'sequence' if 'sequence' in df.columns else df.columns[0]\n","    seqs = df[col].astype(str).tolist()\n","    data_tensor, lengths_tensor = tokenizer.encode_batch(seqs, config[\"max_length\"])\n","    loader = DataLoader(TensorDataset(data_tensor, lengths_tensor), batch_size=config[\"batch_size\"], shuffle=False)\n","\n","    latents_list = []\n","    with torch.no_grad():\n","        for batch, lengths in tqdm(loader):\n","            batch = batch.to(device)\n","            mu = model(batch, lengths) # Using the modified forward for speed\n","            norm_mu = (mu - mu_mean) / mu_std # Apply Stats\n","            latents_list.append(norm_mu.cpu())\n","\n","    final_tensor = torch.cat(latents_list, dim=0)\n","    save_path = os.path.join(\"/content/drive/MyDrive/AMP-Generation/data/\", output_filename)\n","    torch.save(final_tensor, save_path)\n","    print(f\"Success! Saved to {save_path}\")\n","\n","# 7. EXECUTE\n","extract_and_normalize(POS_DATA, \"latent_cond_pos.pth\")\n","extract_and_normalize(NEG_DATA, \"latent_cond_neg.pth\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9CNf3gFqx86p","executionInfo":{"status":"ok","timestamp":1769793212273,"user_tz":-240,"elapsed":13240,"user":{"displayName":"Tamar Vanishvili","userId":"05982125587332184201"}},"outputId":"70204c1b-fb93-4885-a7ed-b03e222b3db4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","Converting pos_data.csv to Latent Space...\n"]},{"output_type":"stream","name":"stderr","text":["Tokenizing: 100%|██████████| 22175/22175 [00:00<00:00, 48966.07it/s]\n","100%|██████████| 6/6 [00:01<00:00,  5.57it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Success! Saved to /content/drive/MyDrive/AMP-Generation/data/latent_cond_pos.pth\n","Converting neg_data.csv to Latent Space...\n"]},{"output_type":"stream","name":"stderr","text":["Tokenizing: 100%|██████████| 22441/22441 [00:00<00:00, 54749.64it/s]\n","100%|██████████| 6/6 [00:00<00:00,  9.60it/s]"]},{"output_type":"stream","name":"stdout","text":["Success! Saved to /content/drive/MyDrive/AMP-Generation/data/latent_cond_neg.pth\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]}]}