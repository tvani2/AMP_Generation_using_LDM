{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mkoko22/AMP_Generation_using_LDM/blob/main/generation/Vae.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 925,
          "referenced_widgets": [
            "387b69c3579e43ad94bd8d081157e4cc",
            "03ed50f921584944b8d601cb5ececd69",
            "fb6bcc1d5d014e4092a37095ff228872",
            "bf61e8e262a6455f8f8d17d83cca2389",
            "9a2ab4effba84d09abbafec262655072",
            "2be690269d024e8aaf94938b38967acb",
            "be25e21794bc45d89c50a5a15bc883f4",
            "695da84c9dbe46c1b9a267ab2a07ed44",
            "f7c985f982b34c2abfb20b3639d5f8ac",
            "64db0af8b2544fedb4b78303b27693fd",
            "62f6bf8e704e47ddabe4a912b3599629",
            "ef124a48cf5241f19795c68e3ea84199",
            "71079be5979144f981c0b5a248fe77ca",
            "f2316d0240ef4b1b8e3f0bd275f23f10",
            "9d9ed3c09c8244d58392e21a15d27698",
            "4e22011ae8a04255a113ff2a4c39bae8",
            "9309945e423c49a388eb4bfd529c957b",
            "f0ab508fa237426a823caf86b03d7f07",
            "cac9540db6004bce90d523287295088e",
            "28dee8f543784e708712fa085b8f5e08",
            "71fee92e07bd41f19019616549c34942",
            "7aad5801da87442593cfc24e2af84d0a",
            "383e51d54f9242b2a52ebe90f4f47706",
            "db38bca58b554f0587eb0c60b2b95cac",
            "69a846e5d6884a24b744835e10228f0c",
            "aa0246b2f0aa40649fbc6748ea0eee4e",
            "ff8d53b6acd04bd8854703219ee059bd",
            "179a764bbd2447a0935d74f26934f7a4",
            "c3b30a8b49b54e68a779a9d9d52bc3fd",
            "d7989f412cc7454db720bb3d6348ac8f",
            "20e3cf09b683478aa8fd6866e71ea475",
            "2da59161ce3d403fa28435b09c42b947",
            "c1d6e5c1e7284e1badf617db9a4e85cb",
            "12143bf3286141ac9fd3728d007d2f24",
            "541344867d5a4afdb7fabdc0af5ee226",
            "6715d2298ae94ea4b9e7f465706f2f7f",
            "56e0ff92f65d40b5af85322026c9498d",
            "aaf97aac3e5e40fe87bd492a5c49eca8",
            "6a9983d33ba4423399a138918e149ee8",
            "4c956a845de0468a8ea9a35de3db25f7",
            "6bbb778960ce46f894c14067ee753752",
            "9eb8b985d8dd45baa5ac906c7f1489ca",
            "2913a4a2388743388d1a6aec493e77f3",
            "f503639a5ae240c9b6bdce91eb3f0535",
            "801cb3ae70a647d8b15b5dc23994b29f",
            "012a253d400c4fb08b51e0d019640c20",
            "b2305dab8f404ed9ba43935a52850c79",
            "0a23a7b12e3b437db21fff0195f0faa1",
            "fb838abe00a14a2d8b7f30779bb7b901",
            "91204c020c5043ee8ab7766d4b599144",
            "ed9b0f53a71a4ec0b2b26f7d2e7c769f",
            "a028b3c0c63149708cc3e9b25f1959e6",
            "c79e8adb54a54e189f291aa3fb7f13e9",
            "39f1375a78db4dd8b98801efb58ef32e",
            "b553ec2f205846d3b4425238b3a3b8a0"
          ]
        },
        "id": "7VOkiwGVvql5",
        "outputId": "172f3432-4df8-49b5-a793-811001f142b0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üöÄ Using Device: cuda\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">hardy-night-8</strong> at: <a href='https://wandb.ai/AMP-Generation/Peptide-Generation-VAE/runs/fsg9mcj9' target=\"_blank\">https://wandb.ai/AMP-Generation/Peptide-Generation-VAE/runs/fsg9mcj9</a><br> View project at: <a href='https://wandb.ai/AMP-Generation/Peptide-Generation-VAE' target=\"_blank\">https://wandb.ai/AMP-Generation/Peptide-Generation-VAE</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20260126_110625-fsg9mcj9/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.24.0"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20260126_110654-8zihzg08</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/AMP-Generation/Peptide-Generation-VAE/runs/8zihzg08' target=\"_blank\">astral-bush-9</a></strong> to <a href='https://wandb.ai/AMP-Generation/Peptide-Generation-VAE' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/AMP-Generation/Peptide-Generation-VAE' target=\"_blank\">https://wandb.ai/AMP-Generation/Peptide-Generation-VAE</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/AMP-Generation/Peptide-Generation-VAE/runs/8zihzg08' target=\"_blank\">https://wandb.ai/AMP-Generation/Peptide-Generation-VAE/runs/8zihzg08</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reading /content/drive/MyDrive/AMP-Generation/data/VAE_train.csv...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "387b69c3579e43ad94bd8d081157e4cc",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Tokenizing:   0%|          | 0/2736731 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reading /content/drive/MyDrive/AMP-Generation/data/VAE_val.csv...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ef124a48cf5241f19795c68e3ea84199",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Tokenizing:   0%|          | 0/143986 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üîÑ Found checkpoint at /content/drive/MyDrive/AMP-Generation/checkpoints/vae_checkpoint.pth. Loading...\n",
            "Successfully resumed from Epoch 17\n",
            "Starting Training from Epoch 18...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "383e51d54f9242b2a52ebe90f4f47706",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Ep 18:   0%|          | 0/669 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ep 18 | Train: 9.9619 | Val: 8.4445\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "12143bf3286141ac9fd3728d007d2f24",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Ep 19:   0%|          | 0/669 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ep 19 | Train: 9.5232 | Val: 11.1394\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "801cb3ae70a647d8b15b5dc23994b29f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Ep 20:   0%|          | 0/669 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ep 20 | Train: 8.9510 | Val: 10.0266\n",
            "\n",
            "üîç SANITY CHECK:\n",
            "Target: MYLSGRGMDYASSWDMIEVVVLTQDKVAGSWPTEAYMDREYLK\n",
            "Pred:   MYLGGRGMDYASSWDMIEVVVLTQDKVGGSWPTAAYMDREYLK\n",
            "------------------------------\n",
            "Target: MDKALKEFEGTVTDVEYDEDEGALITVNVFKGIVDKLYGSK\n",
            "Pred:   MDKALKEFEGTVTDVYYDEDEGALITVNVFKGIVDLLYGSK\n",
            "------------------------------\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train_loss</td><td>‚ñà‚ñÖ‚ñÅ</td></tr><tr><td>val_loss</td><td>‚ñÅ‚ñà‚ñÖ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train_loss</td><td>8.95096</td></tr><tr><td>val_loss</td><td>10.02661</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">astral-bush-9</strong> at: <a href='https://wandb.ai/AMP-Generation/Peptide-Generation-VAE/runs/8zihzg08' target=\"_blank\">https://wandb.ai/AMP-Generation/Peptide-Generation-VAE/runs/8zihzg08</a><br> View project at: <a href='https://wandb.ai/AMP-Generation/Peptide-Generation-VAE' target=\"_blank\">https://wandb.ai/AMP-Generation/Peptide-Generation-VAE</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20260126_110654-8zihzg08/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Complete! Model saved to /content/drive/MyDrive/AMP-Generation/models/vae_final_corrected.pth\n"
          ]
        }
      ],
      "source": [
        "!pip install wandb -q\n",
        "\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import wandb\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from torch.nn.utils.rnn import pack_padded_sequence\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using Device: {device}\")\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "\n",
        "config = {\n",
        "    \"project_name\": \"Peptide-Generation-VAE\",\n",
        "    \"data_path_train\": \"/content/drive/MyDrive/AMP-Generation/data/VAE_train.csv\",\n",
        "    \"data_path_val\":   \"/content/drive/MyDrive/AMP-Generation/data/VAE_val.csv\",\n",
        "    \"checkpoint_dir\":  \"/content/drive/MyDrive/AMP-Generation/checkpoints\",\n",
        "    \"model_dir\":       \"/content/drive/MyDrive/AMP-Generation/models\",\n",
        "    \"checkpoint_file\": \"vae_checkpoint.pth\",\n",
        "\n",
        "    \"max_length\": 50,\n",
        "    \"vocab_size\": 25,\n",
        "    \"embedding_dim\": 128,\n",
        "    \"hidden_dim\": 512,\n",
        "    \"latent_dim\": 64,\n",
        "    \"batch_size\": 4096,\n",
        "    \"learning_rate\": 8e-4,\n",
        "    \"epochs\": 20,\n",
        "    \"kl_weight\": 0.002,\n",
        "}\n",
        "\n",
        "os.makedirs(config[\"checkpoint_dir\"], exist_ok=True)\n",
        "os.makedirs(config[\"model_dir\"], exist_ok=True)\n",
        "\n",
        "try:\n",
        "    wandb.finish()\n",
        "except:\n",
        "    pass\n",
        "wandb.init(project=config[\"project_name\"], config=config)\n",
        "\n",
        "\n",
        "class PeptideTokenizer:\n",
        "    def __init__(self):\n",
        "        self.chars = ['<PAD>', '<SOS>', '<EOS>', '<UNK>'] + list(\"ACDEFGHIKLMNPQRSTVWY\")\n",
        "        self.char_to_idx = {c: i for i, c in enumerate(self.chars)}\n",
        "        self.idx_to_char = {i: c for i, c in enumerate(self.chars)}\n",
        "        self.vocab_size = len(self.chars)\n",
        "\n",
        "    def encode_batch(self, seqs, max_len):\n",
        "        batch_tensor = torch.full((len(seqs), max_len), self.char_to_idx['<PAD>'], dtype=torch.long)\n",
        "        lengths = []\n",
        "        for i, seq in enumerate(tqdm(seqs, desc=\"Tokenizing\")):\n",
        "            s = seq[:max_len - 2]\n",
        "            idx = [self.char_to_idx.get(aa, self.char_to_idx['<UNK>']) for aa in s]\n",
        "            full_seq = [self.char_to_idx['<SOS>']] + idx + [self.char_to_idx['<EOS>']]\n",
        "            length = len(full_seq)\n",
        "            batch_tensor[i, :length] = torch.tensor(full_seq)\n",
        "            lengths.append(length)\n",
        "        return batch_tensor, torch.tensor(lengths, dtype=torch.long)\n",
        "\n",
        "    def decode(self, indices):\n",
        "        res = []\n",
        "        for idx in indices:\n",
        "            if idx == self.char_to_idx['<EOS>']: break\n",
        "            if idx in [self.char_to_idx['<SOS>'], self.char_to_idx['<PAD>']]: continue\n",
        "            res.append(self.idx_to_char[idx])\n",
        "        return \"\".join(res)\n",
        "\n",
        "tokenizer = PeptideTokenizer()\n",
        "config[\"vocab_size\"] = tokenizer.vocab_size\n",
        "\n",
        "def load_and_process_data(path):\n",
        "    print(f\"Reading {path}...\")\n",
        "    df = pd.read_csv(path)\n",
        "    col = 'sequence' if 'sequence' in df.columns else df.columns[0]\n",
        "    seqs = df[col].astype(str).tolist()\n",
        "    data_tensor, lengths_tensor = tokenizer.encode_batch(seqs, config[\"max_length\"])\n",
        "    return TensorDataset(data_tensor, lengths_tensor)\n",
        "\n",
        "train_data = load_and_process_data(config[\"data_path_train\"])\n",
        "val_data = load_and_process_data(config[\"data_path_val\"])\n",
        "\n",
        "train_loader = DataLoader(train_data, batch_size=config[\"batch_size\"], shuffle=True, num_workers=0, pin_memory=True)\n",
        "val_loader = DataLoader(val_data, batch_size=config[\"batch_size\"], shuffle=False, num_workers=0, pin_memory=True)\n",
        "\n",
        "\n",
        "class VAE(nn.Module):\n",
        "    def __init__(self, vocab_size, emb_dim, hidden_dim, latent_dim):\n",
        "        super(VAE, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, emb_dim)\n",
        "        self.encoder_gru = nn.GRU(emb_dim, hidden_dim, batch_first=True, bidirectional=True)\n",
        "        self.fc_mu = nn.Linear(hidden_dim * 2, latent_dim)\n",
        "        self.fc_logvar = nn.Linear(hidden_dim * 2, latent_dim)\n",
        "        self.decoder_input = nn.Linear(latent_dim, hidden_dim)\n",
        "        self.decoder_gru = nn.GRU(emb_dim, hidden_dim, batch_first=True)\n",
        "        self.fc_out = nn.Linear(hidden_dim, vocab_size)\n",
        "\n",
        "    def reparameterize(self, mu, logvar):\n",
        "        std = torch.exp(0.5 * logvar)\n",
        "        eps = torch.randn_like(std)\n",
        "        return mu + eps * std\n",
        "\n",
        "    def forward(self, x, lengths):\n",
        "        embedded = self.embedding(x)\n",
        "        packed_input = pack_padded_sequence(embedded, lengths.cpu(), batch_first=True, enforce_sorted=False)\n",
        "        _, hidden = self.encoder_gru(packed_input)\n",
        "        hidden_cat = torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim=1)\n",
        "        mu = self.fc_mu(hidden_cat)\n",
        "        logvar = self.fc_logvar(hidden_cat)\n",
        "        z = self.reparameterize(mu, logvar)\n",
        "\n",
        "        decoder_hidden = self.decoder_input(z).unsqueeze(0)\n",
        "        dec_input = embedded[:, :-1, :]\n",
        "        outputs, _ = self.decoder_gru(dec_input, decoder_hidden)\n",
        "        logits = self.fc_out(outputs)\n",
        "        return logits, mu, logvar\n",
        "\n",
        "model = VAE(config[\"vocab_size\"], config[\"embedding_dim\"], config[\"hidden_dim\"], config[\"latent_dim\"]).to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=config[\"learning_rate\"])\n",
        "scaler = torch.amp.GradScaler('cuda')\n",
        "\n",
        "start_epoch = 0\n",
        "checkpoint_full_path = os.path.join(config[\"checkpoint_dir\"], config[\"checkpoint_file\"])\n",
        "\n",
        "if os.path.exists(checkpoint_full_path):\n",
        "    print(f\"Found checkpoint at {checkpoint_full_path}. Loading...\")\n",
        "    checkpoint = torch.load(checkpoint_full_path, map_location=device)\n",
        "\n",
        "    if isinstance(checkpoint, dict) and 'model_state_dict' in checkpoint:\n",
        "        model.load_state_dict(checkpoint['model_state_dict'])\n",
        "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "        start_epoch = checkpoint['epoch'] + 1\n",
        "        print(f\"Successfully resumed from Epoch {start_epoch}\")\n",
        "\n",
        "    else:\n",
        "        model.load_state_dict(checkpoint)\n",
        "        print(\"Loaded weights from old format (no epoch info).\")\n",
        "        print(\"Assuming start_epoch = 0\")\n",
        "else:\n",
        "    print(\"No checkpoint found. Starting fresh.\")\n",
        "\n",
        "\n",
        "def vae_loss_function(recon_x, x, mu, logvar):\n",
        "    targets = x[:, 1:]\n",
        "    criterion = nn.CrossEntropyLoss(ignore_index=tokenizer.char_to_idx['<PAD>'], reduction='sum')\n",
        "    recon_loss = criterion(recon_x.reshape(-1, config[\"vocab_size\"]), targets.reshape(-1))\n",
        "    kld_loss = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
        "    return recon_loss, kld_loss\n",
        "\n",
        "def check_reconstruction(model):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        x, l = next(iter(val_loader))\n",
        "        x = x[:2].to(device)\n",
        "        l = l[:2]\n",
        "        logits, _, _ = model(x, l)\n",
        "        preds = torch.argmax(logits, dim=2)\n",
        "        print(\"\\nüîç SANITY CHECK:\")\n",
        "        for i in range(2):\n",
        "            real = tokenizer.decode(x[i, 1:].cpu().numpy())\n",
        "            pred = tokenizer.decode(preds[i].cpu().numpy())\n",
        "            print(f\"Target: {real}\\nPred:   {pred}\\n\" + \"-\"*30)\n",
        "\n",
        "print(f\"Starting Training from Epoch {start_epoch+1}...\")\n",
        "\n",
        "for epoch in range(start_epoch, config[\"epochs\"]):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    progress_bar = tqdm(train_loader, desc=f\"Ep {epoch+1}\", leave=False)\n",
        "\n",
        "    for batch, lengths in progress_bar:\n",
        "        batch = batch.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        with torch.amp.autocast('cuda'):\n",
        "            logits, mu, logvar = model(batch, lengths)\n",
        "            recon_loss, kld_loss = vae_loss_function(logits, batch, mu, logvar)\n",
        "            loss = recon_loss + (config[\"kl_weight\"] * kld_loss)\n",
        "\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.unscale_(optimizer)\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "        total_loss += loss.item()\n",
        "        progress_bar.set_postfix({\"Loss\": loss.item() / batch.size(0)})\n",
        "\n",
        "    avg_loss = total_loss / len(train_loader.dataset)\n",
        "    model.eval()\n",
        "    val_loss = 0\n",
        "    with torch.no_grad():\n",
        "        for batch, lengths in val_loader:\n",
        "            batch = batch.to(device)\n",
        "            logits, mu, logvar = model(batch, lengths)\n",
        "            r, k = vae_loss_function(logits, batch, mu, logvar)\n",
        "            val_loss += (r + config[\"kl_weight\"] * k).item()\n",
        "    avg_val_loss = val_loss / len(val_loader.dataset)\n",
        "\n",
        "    wandb.log({\"train_loss\": avg_loss, \"val_loss\": avg_val_loss})\n",
        "    print(f\"Ep {epoch+1} | Train: {avg_loss:.4f} | Val: {avg_val_loss:.4f}\")\n",
        "\n",
        "    checkpoint_data = {\n",
        "        'epoch': epoch,\n",
        "        'model_state_dict': model.state_dict(),\n",
        "        'optimizer_state_dict': optimizer.state_dict(),\n",
        "        'loss': avg_loss\n",
        "    }\n",
        "    torch.save(checkpoint_data, checkpoint_full_path)\n",
        "\n",
        "    if (epoch+1) % 5 == 0:\n",
        "        check_reconstruction(model)\n",
        "        milestone_path = os.path.join(config[\"model_dir\"], f\"vae_epoch_{epoch+1}.pth\")\n",
        "        torch.save(model.state_dict(), milestone_path)\n",
        "\n",
        "final_path = os.path.join(config[\"model_dir\"], \"vae_final_corrected.pth\")\n",
        "torch.save(model.state_dict(), final_path)\n",
        "wandb.finish()\n",
        "print(f\"Training Complete! Model saved to {final_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aN2OjD6fMUnS",
        "outputId": "df9cd092-22ef-4afa-8e0f-bd7938543d76"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Scanning Latent Space to build Correction File...\n",
            "   Detected Drift -> Mean: -0.01319\n",
            "   Detected Size  -> Std:  1.28643 (Too small, needs scaling)\n",
            "------------------------------\n",
            "CORRECTION FILE SAVED: /content/drive/MyDrive/AMP-Generation/models/vae_correction_stats.pt\n"
          ]
        }
      ],
      "source": [
        "MODEL_PATH = \"/content/drive/MyDrive/AMP-Generation/models/vae_FINAL_epoch20.pth\"\n",
        "SCALER_PATH = \"/content/drive/MyDrive/AMP-Generation/models/vae_correction_stats.pt\"\n",
        "\n",
        "model = VAE(24, 128, 512, 64).to(device)\n",
        "model.load_state_dict(torch.load(MODEL_PATH))\n",
        "model.eval()\n",
        "\n",
        "print(\"Scanning Latent Space to build Correction File...\")\n",
        "all_mus = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch, lengths in train_loader:\n",
        "        batch = batch.to(device)\n",
        "        embedded = model.embedding(batch)\n",
        "        packed = pack_padded_sequence(embedded, lengths.cpu(), batch_first=True, enforce_sorted=False)\n",
        "        _, hidden = model.encoder_gru(packed)\n",
        "        hidden_cat = torch.cat((hidden[-2], hidden[-1]), dim=1)\n",
        "        mu = model.fc_mu(hidden_cat)\n",
        "\n",
        "        all_mus.append(mu)\n",
        "\n",
        "all_mus = torch.cat(all_mus, dim=0)\n",
        "global_mean = all_mus.mean(dim=0)\n",
        "global_std = all_mus.std(dim=0)\n",
        "\n",
        "print(f\"  Detected Drift -> Mean: {global_mean.mean():.5f}\")\n",
        "print(f\"  Detected Size  -> Std:  {global_std.mean():.5f}\")\n",
        "\n",
        "\n",
        "correction_data = {\n",
        "    \"shift\": global_mean,\n",
        "    \"scale\": 1.0 / (global_std + 1e-8)\n",
        "}\n",
        "\n",
        "torch.save(correction_data, SCALER_PATH)\n",
        "print(\"-\" * 30)\n",
        "print(f\"CORRECTION FILE SAVED: {SCALER_PATH}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}